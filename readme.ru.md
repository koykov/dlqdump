# DLQ dump

`dlqdump` это реализация `DLQ` очереди для пакета [`queue`](https://github.com/koykov/queue), которая позволяет дампить
протёкшие элементы в какое-то хранилище: диск, облако, и т.п.

`DLQ` это вспомогательная очередь, куда перенаправляются элементы, которым не нашлось места в очереди по причине
достижения лимита воркеров или по причине ошибки (настраиваемое поведение).

Этот пакет также содержит обратное решение, которое позволяет восстановить элементы из дампа и вернуть их в исходную
очередь (см раздел "Восстановление").

## Дампинг

Дампинг-компонент реализован в виде очереди (т.к. `DLQ` должен реализовывать соответствующий
[интерфейс очереди](https://github.com/koykov/queue/blob/master/interface.go#L4)) и называется также `Queue`. В рамках
этого раздела, под очередью или `Queue` будет подразумеваться именно очередь-дампер, но никак не очередь откуда
поступают данные, кроме специально оговоренных случаев (термин "исходная очередь").

Очередь инициализируется с помощью структуры
[`Config`](https://github.com/koykov/dlqdump/blob/master/config.go#L18).

Базовый параметр конфига это `Version`. Позволяет задать версию дампа, которая будет проверяться при чтении из дампа и
укажет являются ли дамп-данные обратно совместимыми (фактически, можно ли попробовать их вернуть в исходную очередь).

### Настройки сброса

Далее параметрами `Capacity` и `FlushInterval` настраивается как часто очереди будет необходимо "сбрасывать" данные в
хранилище. `Capacity` ограничивает максимальную ёмкость очереди в байтах, а `FlushInterval` ограничивает сколько очередь
может ждать поступления данных до сброса (начиная с момента поступления первого элемента).

Это требует пояснения. `Capacity` измеряется именно в байтах, а не элементах потому, что предполагается сброс данных в
хранилище, которое может ограничивать размер (например какое-то облачное хранилище с ограничением на размер файлов).
Таким образом очередь может накопить только определённое количество сериализованных данных (см. раздел "Сериализация") и
произведёт сброс данных в хранилище по достижении этого лимита. Этот параметр является обязательным.

Паралельно работает ограничение по `FlushInterval`. Запоминается момент поступления первого элемента (с начала работы
очереди или с момента последнего сброса) и по прошествии `FlushInterval`происходит сброс с причиной "достигнут интервал".
Такое поведение необходимо для случаев, когда элементы поступают очень редко и не способны заполнить очередь до
`Capacity` лимита. Благодаря `FlushInterval` элементы не будут висеть бесконечно в очереди и будут сброшены в хранилище,
пусть даже размер порции будет маленьким.

Итого получается, что очередь ждёт поступления новых элементов, обрабатывает их и следит что наступит первым: будет
достигнут `Capacity` лимит или пройдёт `FlushInterval`. Затем произойдёт сброс в хранилище.

Замечу, что при закрытии очереди, содержащей данные, произойдёт принудительный сброс, без учёта обоих параметров и
только затем очередь будет закрыта.

### Сериализация

`Queue` имеет два уровня абстракции. Первый задаётся параметром `Encoder`. Это специальный компонент, который должен
реализовывать интерфейс [`Encoder`](https://github.com/koykov/dlqdump/blob/master/encoder.go). Этот компонент принимает
произвольный элеменент и пробует его сериализовать в буфер `dst`. Сериализованные данные будут далее перенаправлены в
хранилище.

`dlqdump` из коробки содержит несколько енкодеров:
[builtin](https://github.com/koykov/dlqdump/blob/master/encoder/builtin.go) и
[marshaller](https://github.com/koykov/dlqdump/blob/master/encoder/marshaller.go).
Первый позволяет сериализовать примитивные строковые типы данных, а также объекты реализующие `Byter` и `Stringer`
интерфейсы.
Второй интереснее, с его помощью можно сериализовать сложные структуры, например
[protobuf](https://en.wikipedia.org/wiki/Protocol_Buffers) объекты.

### Запись дампов

Это второй слой абстракции. Он задаётся параметром `Writer` и должен реализовывать интерфейс
[`Writer`](https://github.com/koykov/dlqdump/blob/master/writer.go). Этот объект, согласно своей внутренней логике,
использует переданные очередью версию и сериализованные `Encoder`-ом данные для создания дампов. Например, `dlqdump` из
коробки содержит реализацию `Writer`-а, которая [пишет данные на диск](https://github.com/koykov/dlqdump/tree/master/fs).
Но вы можете написать любую удобную вам реализацию, например для записи в Google Cloud или куда-то ещё.

## Восстановление

`dlqdump` имеет специальное решение `Restorer`, обратное `Queue`. Этот компонент способен читать данные из дампа с
последующей отправкой в какую-то очередь.

Идея была такова: исходная очередь протекает и через `DLQ` отправляет элементы в очередь-дампер. Она сбрасывает данные
в хранилище и затем `Restorer` с определённой периодичностью их читает и пробует отправлять в очередь-адресат
(предполагается, что это исходная очередь, но это необязательно).
Получается замкнутая петля, котрая позволит не потерять важные элементы. При этом хранилище будет использовано как буфер
очень большой ёмкости, что позволит не потреблять бесконтрольно память приложения.

`Restorer` использует ту же структуру `Config`, что и `Queue`, но игнорирует специфичные для очереди параметры
(кстати, аналогично очередь игнорирует параметры `Restorer`-а).

Базовой настройкой компонента является параметр `Version`. Его назначение аналогично конфигу `Queue`. При чтении дампа
проверяются версии в дампе и в конфиге. В случае несовпадения дамп будет признан обратно несовместимым и удалён.

Очередь-адресат задаётся параметром `Queue` и должна реализовывать
[интерфейс очереди](https://github.com/koykov/queue/blob/master/interface.go#L4). В неё будут направлены восстановленные
элементы.

### Настройки восстановления

`Restorer` имеет три настройки, согласно которым проиходит восстановление данных и отправка в очередь-адресат:
`CheckInterval`, `PostponeInterval`, `AllowRate`.

Параметр `CheckInterval` задаёт периодичность проверки хранилища на наличие дампов.

Параметр `PostponeInterval` задержит отправку восстановленного элемента в очередь-адресат, если её
[рейт](https://github.com/koykov/queue/blob/master/interface.go#L12) превышает `AllowRate` параметр. Так `Restorer` не
сможет перегрузить очередь-адресат востановленными элементами.

### Чтение дампов

`Restorer` подобно `Queue` имеет два слоя абстракции, но с обратным смыслом.

Первый задаётся параметром `Reader`, который должен реализовывать интерфейс
[`Reader`](https://github.com/koykov/dlqdump/blob/master/reader.go). В общем виде, этот компонент должен читать из дампа
сериализованные данные и версию до тех пор, пока не вернёт `EOF` ошибку.
`dlqdump` из коробки содержит реализацию `Reader`-а, которая
[читает дампы с диска](https://github.com/koykov/dlqdump/tree/master/fs).
Вы вольны написать свою реализацию чтения дампов из нужного источника.

После успешного чтения происходит проверка версий.

### Десериализация

Полученные из `Reader`-а сериализованные данные будут переданы в параметр `Decoder`. Это специальный компонент,
реализующий интерфейс [`Decoder`](https://github.com/koykov/dlqdump/blob/master/decoder.go). Он или сможет
десериализовать исходный элемент или сообщит о невозможности сделать это. Этот компонент является вторым слоем
абстракции.
`dlqdump` из коробки имеет два декодера:
[fallthrough](https://github.com/koykov/dlqdump/blob/master/decoder/fallthrough.go) и
[unmarshaller](https://github.com/koykov/dlqdump/blob/master/decoder/unmarshaller.go). Первый был разработан для нужд
тестирования и не имеет смысла в продакшн условиях. А второй обратен енкодеру `marshaller` и способен десериализовать
сложные объекты вроде `protobuf`.

В случае успешной десериализации полученный элемент будет отправлен в очередь-адресат.

## Метрики

Аналогично [`queue`](https://github.com/koykov/queue) `dlqdump` имеет параметр `MetricsWriter` где можно задать объект,
реализующий интерфейс [`MetricsWriter`](https://github.com/koykov/dlqdump/blob/master/metrics.go#L4). Описание всех
методов см. в исходном коде интерфейса, он достаточно простой.

На данный момент написаны две реализации этого интерфейса:
[`LogMetrics`](https://github.com/koykov/dlqdump/blob/master/metrics/log/log.go) и
[`PrometheusMetrics`](https://github.com/koykov/dlqdump/blob/master/metrics/prometheus/prometheus.go). Первый бесмысленно
использовать в продакшн условиях и он создавался для упрощения отладки при разработке. А вот Prometheus версия полностью
рабочая и протестированная. Аналогичным образом, можно написать реализацию `MetricsWriter`-а для иной TSDB, которую вы
используете.

## Логирование

`Restorer` умеет логировать свои внутренние процессы с помощью параметра `Logger`, куда можно задать логгер, реализующий
интерфейс [`Logger`](https://github.com/koykov/queue/blob/master/logger.go). Он очень простой и пригодится только для
отладочных и/или демонстраницонных целей.

## Demo сцена

`dlqdump` использует тот же [демонстрационный проект](https://github.com/koykov/demo/tree/master/queue) для отладки и
тестирования, что и `queue`.

Сценарий тестирования с `dlqdump` https://github.com/koykov/demo/blob/master/queue/request/demo100k_dump.http

## Ссылки

* https://en.wikipedia.org/wiki/Dead_letter_queue
* https://cloud.yandex.com/en/docs/message-queue/concepts/dlq
